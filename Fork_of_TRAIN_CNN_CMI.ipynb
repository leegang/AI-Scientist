{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 102335,
          "databundleVersionId": 12518947,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Fork of TRAIN-CNN_CMI",
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b28f088d95a404798b089bdeeb82741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75df0ebe36324f788ae1c8a6c31ca7de"
            ],
            "layout": "IPY_MODEL_0cd469654cab427680e0d0363a70ee61"
          }
        },
        "197ae036a66b49d6b604fdd8c3729ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00fb8a484696460ab01c125b841d548f",
            "placeholder": "​",
            "style": "IPY_MODEL_e885eb1d158d4e4f9dbba585c6bda811",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "af7ec867856c4133b9d73b8830890973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_2eca384fb1eb4ad7aa5f491842352c03",
            "placeholder": "​",
            "style": "IPY_MODEL_38cddb37a34d4cc5a11d8b4b89909f23",
            "value": "logiclab"
          }
        },
        "23dff1a945cf439d81e255ecf4145c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_fcf060379e354c07b299653dcc8ae14a",
            "placeholder": "​",
            "style": "IPY_MODEL_c895124c268a415996c96563e901df0b",
            "value": ""
          }
        },
        "3489905c84bd474ca9dab774c1542460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3d1d3e5e2b394ab686bdbf3f8f9989cb",
            "style": "IPY_MODEL_742b2fdde3db45b190bfb275e72acae7",
            "tooltip": ""
          }
        },
        "9cdc2e72929b4f9ebdd45001f1413d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2e7e23a1224245a4a6ded4c938ec10",
            "placeholder": "​",
            "style": "IPY_MODEL_45d314b646a949a4adff081dcc4e7fc8",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "0cd469654cab427680e0d0363a70ee61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "00fb8a484696460ab01c125b841d548f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e885eb1d158d4e4f9dbba585c6bda811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eca384fb1eb4ad7aa5f491842352c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38cddb37a34d4cc5a11d8b4b89909f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf060379e354c07b299653dcc8ae14a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c895124c268a415996c96563e901df0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d1d3e5e2b394ab686bdbf3f8f9989cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742b2fdde3db45b190bfb275e72acae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "da2e7e23a1224245a4a6ded4c938ec10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d314b646a949a4adff081dcc4e7fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfa88df0e5194c10bcb24b816c2f176e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc31ac5f0de4b01b9e5685121ac1e31",
            "placeholder": "​",
            "style": "IPY_MODEL_f03502eff6bc4fa09be356e2ac5f42a1",
            "value": "Connecting..."
          }
        },
        "4cc31ac5f0de4b01b9e5685121ac1e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03502eff6bc4fa09be356e2ac5f42a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75df0ebe36324f788ae1c8a6c31ca7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb1e03c18da4ff7ba04731ebf1775b5",
            "placeholder": "​",
            "style": "IPY_MODEL_137ba449cc3e40e788480575eabb7303",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "6fb1e03c18da4ff7ba04731ebf1775b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137ba449cc3e40e788480575eabb7303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eef72f2e230c4a4593cb8e7a8de9fb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_534e9c55d6d749d48d04d6de7c7a9653",
              "IPY_MODEL_7b09abe413b5457b9f3d39b904d863be",
              "IPY_MODEL_91443d27c8274f6f82f5ce057283104e"
            ],
            "layout": "IPY_MODEL_0d214fa8511a472292f1d4c9ef6e41a9"
          }
        },
        "534e9c55d6d749d48d04d6de7c7a9653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d38975a22b5c40b0b9086d0b66e8934d",
            "placeholder": "​",
            "style": "IPY_MODEL_59674fc19b6e4643b403bdd392501ec7",
            "value": "Angular Velocity: 100%"
          }
        },
        "7b09abe413b5457b9f3d39b904d863be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e18879f8d145c4a626f213c51ce0f5",
            "max": 8151,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c12dbbd7ee534710972601d0299e0fd1",
            "value": 8151
          }
        },
        "91443d27c8274f6f82f5ce057283104e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6af6aedfca4348d788650d24f00021b6",
            "placeholder": "​",
            "style": "IPY_MODEL_1c35f7b923794dd893f0a574417a9bcd",
            "value": " 8151/8151 [00:07&lt;00:00, 1260.42it/s]"
          }
        },
        "0d214fa8511a472292f1d4c9ef6e41a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d38975a22b5c40b0b9086d0b66e8934d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59674fc19b6e4643b403bdd392501ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e18879f8d145c4a626f213c51ce0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12dbbd7ee534710972601d0299e0fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6af6aedfca4348d788650d24f00021b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c35f7b923794dd893f0a574417a9bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc5e41b598bc4b2ab12295bf3f7e51d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5d9bb8a68c64688a117053cf8736c0f",
              "IPY_MODEL_1bfd2910296e4ea7ba7e4e377a3c696e",
              "IPY_MODEL_440ec29047c844e08b6524f6cdcf7860"
            ],
            "layout": "IPY_MODEL_c8c1c80348ce434bb07bbad6c55bccf3"
          }
        },
        "e5d9bb8a68c64688a117053cf8736c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02a87a6f786c4d41ba736eba5ac88cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_7f0f494cc0f24e93ad54820039c28012",
            "value": "Dispatching save jobs:   2%"
          }
        },
        "1bfd2910296e4ea7ba7e4e377a3c696e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca5a27fff4704b868f607f373a73dee7",
            "max": 8151,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c14e88a36ec14d65b2c34593b15b53cc",
            "value": 145
          }
        },
        "440ec29047c844e08b6524f6cdcf7860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7141ef5b9644c89c5e15e79051ddd3",
            "placeholder": "​",
            "style": "IPY_MODEL_3c4ac08f0f6c421e8fdb2fcef6a770da",
            "value": " 145/8151 [00:22&lt;21:32,  6.19it/s]"
          }
        },
        "c8c1c80348ce434bb07bbad6c55bccf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02a87a6f786c4d41ba736eba5ac88cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0f494cc0f24e93ad54820039c28012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca5a27fff4704b868f607f373a73dee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14e88a36ec14d65b2c34593b15b53cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e7141ef5b9644c89c5e15e79051ddd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c4ac08f0f6c421e8fdb2fcef6a770da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leegang/AI-Scientist/blob/main/Fork_of_TRAIN_CNN_CMI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "QXRfQqWfWi7d",
        "outputId": "efe59d0c-9226-4ab8-a92b-777c4b3672db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "2b28f088d95a404798b089bdeeb82741",
            "197ae036a66b49d6b604fdd8c3729ccf",
            "af7ec867856c4133b9d73b8830890973",
            "23dff1a945cf439d81e255ecf4145c0a",
            "3489905c84bd474ca9dab774c1542460",
            "9cdc2e72929b4f9ebdd45001f1413d2f",
            "0cd469654cab427680e0d0363a70ee61",
            "00fb8a484696460ab01c125b841d548f",
            "e885eb1d158d4e4f9dbba585c6bda811",
            "2eca384fb1eb4ad7aa5f491842352c03",
            "38cddb37a34d4cc5a11d8b4b89909f23",
            "fcf060379e354c07b299653dcc8ae14a",
            "c895124c268a415996c96563e901df0b",
            "3d1d3e5e2b394ab686bdbf3f8f9989cb",
            "742b2fdde3db45b190bfb275e72acae7",
            "da2e7e23a1224245a4a6ded4c938ec10",
            "45d314b646a949a4adff081dcc4e7fc8",
            "bfa88df0e5194c10bcb24b816c2f176e",
            "4cc31ac5f0de4b01b9e5685121ac1e31",
            "f03502eff6bc4fa09be356e2ac5f42a1",
            "75df0ebe36324f788ae1c8a6c31ca7de",
            "6fb1e03c18da4ff7ba04731ebf1775b5",
            "137ba449cc3e40e788480575eabb7303"
          ]
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b28f088d95a404798b089bdeeb82741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "cmi_detect_behavior_with_sensor_data_path = kagglehub.competition_download('cmi-detect-behavior-with-sensor-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GqCdzaSBWi7h",
        "outputId": "994859ef-b760-44cb-8770-5685913cb2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/cmi-detect-behavior-with-sensor-data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 178M/178M [00:01<00:00, 107MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars"
      ],
      "metadata": {
        "id": "Eb8s2QvXW-zm",
        "outputId": "74c237ef-afc6-4b4e-df27-4c7d602d6c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polars\n",
            "  Downloading polars-1.31.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Downloading polars-1.31.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.1/35.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polars\n",
            "Successfully installed polars-1.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CELL1"
      ],
      "metadata": {
        "id": "3aQsap-qWi7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# 1. SETUP AND CONFIGURATION\n",
        "# ====================================================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "import polars as pl\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "import joblib"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "_Grfkcg_Wi7o"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CEll 2"
      ],
      "metadata": {
        "id": "__OOxJp9Wi7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# 2. CONFIGURATION\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    # 数据路径\n",
        "    DATA_DIR = \"/root/.cache/kagglehub/competitions/cmi-detect-behavior-with-sensor-data/\"\n",
        "    TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
        "    TRAIN_DEMO_CSV = os.path.join(DATA_DIR, \"train_demographics.csv\")\n",
        "\n",
        "    # 预处理数据路径\n",
        "    PREPROCESSED_DIR = \"/kaggle/working/preprocessed_data/\"\n",
        "    RUN_PREPROCESSING = not os.path.exists(PREPROCESSED_DIR) # 检查目录是否存在\n",
        "\n",
        "    # 时序数据参数\n",
        "    TARGET_SEQ_LEN = 512\n",
        "\n",
        "    # 训练参数\n",
        "    # MODEL_NAME = 'Custom1DCNN'\n",
        "    N_FOLDS = 6\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS =  60\n",
        "    LEARNING_RATE =  1e-4\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    HIERARCHICAL_LOSS_ALPHA = 0.1\n",
        "\n",
        "    # 输出路径\n",
        "    MODEL_OUTPUT_DIR = \"/kaggle/working/models/\"\n",
        "\n",
        "    # 特征列\n",
        "    DEMO_COLS = ['adult_child', 'age', 'sex', 'handedness',\n",
        "                 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm',\n",
        "                 'shoulder_wrist_ratio', 'elbow_wrist_ratio']\n",
        "\n",
        "# 创建必要的目录\n",
        "os.makedirs(CFG.MODEL_OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EamDZqYLWi7q"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CELL3"
      ],
      "metadata": {
        "id": "o1QRG3wSWi7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# CELL: PRE-PROCESSING & FEATURE ENGINEERING (OPTIMIZED & ENHANCED)\n",
        "# ====================================================================\n",
        "\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import joblib\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from tqdm.auto import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "\n",
        "def calculate_angular_velocity_vectorized(quat_values):\n",
        "    \"\"\"向量化版本：从四元数计算角速度。\"\"\"\n",
        "    # 计算四元数的时间差分\n",
        "    # q_t * conj(q_{t-1})\n",
        "    q_diff = np.zeros_like(quat_values)\n",
        "\n",
        "    # 填充第一个时间步的差分（保持为0）\n",
        "    q_diff[1:] = R.from_quat(quat_values[1:]) * R.from_quat(quat_values[:-1]).inv()\n",
        "\n",
        "    # 从差分四元数中提取旋转向量（其模长是角度，方向是轴）\n",
        "    # 角速度约等于 旋转向量 / dt。这里我们假设 dt=1，所以角速度就是旋转向量。\n",
        "    angular_velocity = q_diff.as_rotvec()\n",
        "\n",
        "    return angular_velocity\n",
        "\n",
        "# --- 辅助函数 ---\n",
        "\n",
        "def remove_gravity_from_acc_vectorized(acc_values, quat_values):\n",
        "    \"\"\"\n",
        "    向量化版本: 从加速度数据中移除重力分量。\n",
        "    在整个数据集的Numpy数组上一次性操作。\n",
        "    \"\"\"\n",
        "    num_samples = acc_values.shape[0]\n",
        "    linear_accel = np.zeros_like(acc_values)\n",
        "    gravity_world = np.array([0, 0, 9.81]) # 标准重力加速度\n",
        "\n",
        "    # 识别有效的四元数行 (非NaN, 非零)\n",
        "    valid_quat_mask = ~np.all(np.isnan(quat_values), axis=1) & ~np.all(np.isclose(quat_values, 0), axis=1)\n",
        "\n",
        "    # 默认情况下，线性加速度等于原始加速度\n",
        "    linear_accel = acc_values.copy()\n",
        "\n",
        "    if np.any(valid_quat_mask):\n",
        "        valid_acc = acc_values[valid_quat_mask]\n",
        "        valid_quat = quat_values[valid_quat_mask]\n",
        "\n",
        "        try:\n",
        "            # Scipy可以批量处理四元数，效率极高\n",
        "            rotations = R.from_quat(valid_quat)\n",
        "            gravity_sensor_frame = rotations.apply(gravity_world, inverse=True)\n",
        "            linear_accel[valid_quat_mask] = valid_acc - gravity_sensor_frame\n",
        "        except ValueError as e:\n",
        "            print(f\"Warning: A portion of quaternion conversion failed: {e}. Falling back for those rows.\")\n",
        "            # 如果批量处理失败（例如，由于无效的四元数值），可以回退到循环处理\n",
        "            # 但在大多数情况下，Scipy的批量处理是稳健的\n",
        "\n",
        "    return linear_accel\n",
        "\n",
        "def euler_from_quat_vectorized(quat_values):\n",
        "    \"\"\"向量化版本: 将四元数转换为欧拉角 (roll, pitch, yaw)。\"\"\"\n",
        "    euler_angles = np.zeros((quat_values.shape[0], 3))\n",
        "\n",
        "    valid_quat_mask = ~np.all(np.isnan(quat_values), axis=1) & ~np.all(np.isclose(quat_values, 0), axis=1)\n",
        "\n",
        "    if np.any(valid_quat_mask):\n",
        "        valid_quat = quat_values[valid_quat_mask]\n",
        "        try:\n",
        "            rotations = R.from_quat(valid_quat)\n",
        "            # as_eul('xyz', degrees=False) 返回 roll, pitch, yaw (弧度)\n",
        "            euler_angles[valid_quat_mask] = rotations.as_euler('xyz', degrees=False)\n",
        "        except ValueError:\n",
        "            print(\"Warning: Euler angle conversion failed for a portion of data.\")\n",
        "\n",
        "    return euler_angles\n",
        "\n",
        "\n",
        "def process_and_save_group(group_data, seq_id, sensor_cols, preprocessed_dir, target_seq_len):\n",
        "    \"\"\"\n",
        "    处理单个序列的 Polars DataFrame，统一长度，然后保存为 .npy。\n",
        "    这个函数是为并行化设计的。\n",
        "    \"\"\"\n",
        "    # 1. 选择最终需要的列并填充空值\n",
        "    processed_df = group_data.select(sensor_cols).fill_null(0)\n",
        "\n",
        "    # 2. ToF=-1 to 255 的处理 (已在 Polars 中完成，这里不需要)\n",
        "\n",
        "    # 3. 转换为 Numpy 数组\n",
        "    ts_data = processed_df.to_numpy() # Shape: (L, C)\n",
        "\n",
        "    # 4. 统一序列长度\n",
        "    current_seq_len = ts_data.shape[0]\n",
        "    if current_seq_len < target_seq_len:\n",
        "        # 如果序列太短，用0填充\n",
        "        padding_shape = (target_seq_len - current_seq_len, ts_data.shape[1])\n",
        "        padding = np.zeros(padding_shape, dtype=ts_data.dtype)\n",
        "        final_data = np.vstack((ts_data, padding))\n",
        "    else:\n",
        "        # 如果序列太长，从开头截断\n",
        "        final_data = ts_data[:target_seq_len, :]\n",
        "\n",
        "    # 5. 转置以匹配 (C, L) 的格式并保存\n",
        "    ts_data_processed = final_data.T\n",
        "    np.save(os.path.join(preprocessed_dir, f\"{seq_id}.npy\"), ts_data_processed)\n",
        "\n",
        "# =============================================================================\n",
        "# 主预处理逻辑\n",
        "# =============================================================================\n",
        "\n",
        "# 假设 CFG 已经定义好\n",
        "# CFG.RUN_PREPROCESSING, CFG.PREPROCESSED_DIR, CFG.TRAIN_CSV, CFG.TARGET_SEQ_LEN etc.\n",
        "\n",
        "if CFG.RUN_PREPROCESSING:\n",
        "    # 1. 清理旧目录\n",
        "    if os.path.exists(CFG.PREPROCESSED_DIR):\n",
        "        print(f\"Removing old preprocessed data at: {CFG.PREPROCESSED_DIR}\")\n",
        "        shutil.rmtree(CFG.PREPROCESSED_DIR)\n",
        "    os.makedirs(CFG.PREPROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "    # 2. 加载原始CSV (使用 Polars 的 Lazy API 以节省内存)\n",
        "    print(\"Reading original CSV using Polars LazyFrame...\")\n",
        "    lazy_df = pl.scan_csv(CFG.TRAIN_CSV)\n",
        "\n",
        "    # 3. 特征工程 (所有操作都在 Polars LazyFrame 上定义)\n",
        "    print(\"Defining feature engineering steps...\")\n",
        "\n",
        "    # 处理 ToF 缺失值\n",
        "    tof_cols = [c for c in lazy_df.columns if 'tof_' in c]\n",
        "    if tof_cols:\n",
        "        replace_exprs = [pl.when(pl.col(c) == -1).then(255).otherwise(pl.col(c)).alias(c) for c in tof_cols]\n",
        "        lazy_df = lazy_df.with_columns(replace_exprs)\n",
        "\n",
        "    # --- 执行需要 Numpy 的特征工程 ---\n",
        "    print(\"Executing vectorized feature engineering (Gravity, Euler)...\")\n",
        "    # collect() 执行计算，将 LazyFrame 物化为 DataFrame 以便与 Numpy 交互\n",
        "    train_df = lazy_df.collect()\n",
        "\n",
        "    # a. 移除重力\n",
        "    acc_data = train_df.select(['acc_x', 'acc_y', 'acc_z']).to_numpy()\n",
        "    rot_data = train_df.select(['rot_x', 'rot_y', 'rot_z', 'rot_w']).to_numpy()\n",
        "    linear_accel_data = remove_gravity_from_acc_vectorized(acc_data, rot_data)\n",
        "    linear_accel_df = pl.from_numpy(linear_accel_data, schema=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'])\n",
        "\n",
        "    # b. 计算欧拉角\n",
        "    euler_angles_data = euler_from_quat_vectorized(rot_data)\n",
        "    euler_df = pl.from_numpy(euler_angles_data, schema=['roll', 'pitch', 'yaw'])\n",
        "\n",
        "     # ‼️ c. 新增：计算角速度 ‼️\n",
        "    print(\"Calculating angular velocity per sequence...\")\n",
        "    train_pd = train_df.to_pandas()\n",
        "    # 填充NaN值\n",
        "    quat_cols = ['rot_x', 'rot_y', 'rot_z', 'rot_w']\n",
        "    train_pd[quat_cols] = train_pd[quat_cols].fillna(0)\n",
        "\n",
        "    # ‼️‼️ 修正点在这里 ‼️‼️\n",
        "    def quat_diff_to_angular_vel(group):\n",
        "        quat_values = group[quat_cols].values\n",
        "\n",
        "        # 安全检查：找到零范数的四元数\n",
        "        norms = np.linalg.norm(quat_values, axis=1)\n",
        "        zero_norm_mask = (norms == 0)\n",
        "\n",
        "        # 如果存在零范数，则将其替换为单位四元数 [0, 0, 0, 1]\n",
        "        if np.any(zero_norm_mask):\n",
        "            quat_values[zero_norm_mask] = [0, 0, 0, 1]\n",
        "\n",
        "        try:\n",
        "            q = R.from_quat(quat_values)\n",
        "            angular_vel = np.zeros((len(group), 3))\n",
        "            if len(group) > 1:\n",
        "                # 计算差分旋转并提取角速度向量\n",
        "                # q[1:] * q[:-1].inv() -> 从 t-1 到 t 的旋转\n",
        "                # .as_rotvec() -> 将该旋转表示为 (轴*角度) 的向量\n",
        "                angular_vel[1:] = (q[1:] * q[:-1].inv()).as_rotvec()\n",
        "            return pd.DataFrame(angular_vel, index=group.index, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'])\n",
        "        except ValueError as e:\n",
        "            # 添加一个备用错误处理，以防还有其他问题\n",
        "            print(f\"Warning: Could not process quaternions for a group in sequence {group['sequence_id'].iloc[0]}. Error: {e}. Filling with zeros.\")\n",
        "            return pd.DataFrame(np.zeros((len(group), 3)), index=group.index, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'])\n",
        "\n",
        "\n",
        "    angular_vel_list = [quat_diff_to_angular_vel(group) for _, group in tqdm(train_pd.groupby('sequence_id'), desc=\"Angular Velocity\")]\n",
        "    angular_vel_pd = pd.concat(angular_vel_list)\n",
        "    angular_vel_df = pl.from_pandas(angular_vel_pd)\n",
        "\n",
        "    # 将新特征合并回主 DataFrame\n",
        "    train_df = train_df.hstack(linear_accel_df).hstack(euler_df).hstack(angular_vel_df)\n",
        "\n",
        "    # --- 在 Polars 中继续进行其他特征工程 ---\n",
        "    print(\"Engineering Mag, Jerk, and Rolling features in Polars...\")\n",
        "\n",
        "    # 定义窗口大小\n",
        "    WINDOW_SIZE = 10\n",
        "\n",
        "    # 计算模 (Magnitude)\n",
        "    train_df = train_df.with_columns([\n",
        "        (pl.col('linear_acc_x')**2 + pl.col('linear_acc_y')**2 + pl.col('linear_acc_z')**2).sqrt().alias('linear_acc_mag'),\n",
        "        (pl.col('rot_x')**2 + pl.col('rot_y')**2 + pl.col('rot_z')**2).sqrt().alias('rot_vel_mag')\n",
        "    ])\n",
        "\n",
        "    # 计算Jerk (加加速度) - 按序列分组计算差分\n",
        "    jerk_cols = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n",
        "    train_df = train_df.with_columns([\n",
        "        pl.col(c).diff().over('sequence_id').alias(f\"{c.replace('linear_acc', 'jerk')}\") for c in jerk_cols\n",
        "    ])\n",
        "\n",
        "    # 计算滑动窗口统计特征 (均值和标准差)\n",
        "    # 筛选出要计算滚动特征的列 (例如所有加速度和陀螺仪)\n",
        "    rolling_feature_cols = [c for c in train_df.columns if 'acc_' in c or 'rot_' in c or 'jerk' in c]\n",
        "    train_df = train_df.with_columns([\n",
        "        pl.col(c).rolling_mean(window_size=WINDOW_SIZE, min_periods=1).over('sequence_id').alias(f'{c}_rolling_mean_{WINDOW_SIZE}')\n",
        "        for c in rolling_feature_cols\n",
        "    ] + [\n",
        "        pl.col(c).rolling_std(window_size=WINDOW_SIZE, min_periods=1).over('sequence_id').alias(f'{c}_rolling_std_{WINDOW_SIZE}')\n",
        "        for c in rolling_feature_cols\n",
        "    ])\n",
        "\n",
        "    # ‼️ 新增：计算聚合统计特征 (按 sequence_id 分组) ‼️\n",
        "    tof_pixel_cols = [c for c in train_df.columns if 'tof_' in c and '_v' in c]\n",
        "    thm_cols = [c for c in train_df.columns if 'thm_' in c and c.endswith(tuple(map(str, range(1, 6))))]\n",
        "\n",
        "    agg_exprs = []\n",
        "    # 1. TOF 传感器内部聚合\n",
        "    for i in range(1, 6):\n",
        "        sensor_tof_cols = [c for c in tof_pixel_cols if f\"tof_{i}_\" in c]\n",
        "        if sensor_tof_cols:\n",
        "            # 创建一个表达式列表，用于处理 255 -> null\n",
        "            cols_expr_for_agg = [pl.when(pl.col(c) == 255).then(None).otherwise(pl.col(c)) for c in sensor_tof_cols]\n",
        "\n",
        "            # 计算横向均值\n",
        "            mean_expr = pl.mean_horizontal(cols_expr_for_agg)\n",
        "\n",
        "            # ‼️‼️ 修正点在这里：手动实现横向标准差 ‼️‼️\n",
        "            # std = sqrt( mean(x^2) - (mean(x))^2 )\n",
        "            mean_of_squares_expr = pl.mean_horizontal([e**2 for e in cols_expr_for_agg])\n",
        "            variance_expr = mean_of_squares_expr - mean_expr**2\n",
        "            # 加一个小的 epsilon 防止开方负数\n",
        "            std_expr = variance_expr.clip(lower_bound=1e-8).sqrt()\n",
        "\n",
        "            agg_exprs.extend([\n",
        "                mean_expr.alias(f'tof_{i}_mean'),\n",
        "                std_expr.alias(f'tof_{i}_std'), # <-- 使用我们手动构造的表达式\n",
        "                pl.min_horizontal(cols_expr_for_agg).alias(f'tof_{i}_min'),\n",
        "                pl.max_horizontal(cols_expr_for_agg).alias(f'tof_{i}_max'),\n",
        "            ])\n",
        "\n",
        "    # 执行第一批聚合计算\n",
        "    train_df = train_df.with_columns(agg_exprs)\n",
        "\n",
        "    # 2. 跨传感器聚合\n",
        "    tof_mean_cols = [f'tof_{i}_mean' for i in range(1, 6)]\n",
        "    thm_cols = [f'thm_{i}' for i in range(1, 6)] # 确保 thm_cols 也是正确的\n",
        "\n",
        "    # ‼️‼️ 同样需要手动实现跨传感器的横向标准差 ‼️‼️\n",
        "    tof_mean_across_expr = pl.mean_horizontal(tof_mean_cols)\n",
        "    tof_var_across_expr = pl.mean_horizontal([pl.col(c)**2 for c in tof_mean_cols]) - tof_mean_across_expr**2\n",
        "    tof_std_across_expr = tof_var_across_expr.clip(lower_bound=1e-8).sqrt()\n",
        "\n",
        "    thm_mean_across_expr = pl.mean_horizontal(thm_cols)\n",
        "    thm_var_across_expr = pl.mean_horizontal([pl.col(c)**2 for c in thm_cols]) - thm_mean_across_expr**2\n",
        "    thm_std_across_expr = thm_var_across_expr.clip(lower_bound=1e-8).sqrt()\n",
        "\n",
        "    train_df = train_df.with_columns([\n",
        "        (pl.max_horizontal(tof_mean_cols) - pl.min_horizontal(tof_mean_cols)).alias('tof_range_across_sensors'),\n",
        "        tof_std_across_expr.alias('tof_std_across_sensors'), # <-- 使用新表达式\n",
        "        (pl.max_horizontal(thm_cols) - pl.min_horizontal(thm_cols)).alias('thm_range_across_sensors'),\n",
        "        thm_std_across_expr.alias('thm_std_across_sensors'), # <-- 使用新表达式\n",
        "    ])\n",
        "\n",
        "    print(\"Feature engineering complete.\")\n",
        "\n",
        "    # 4. 定义并保存最终的特征列列表\n",
        "    # ‼️ SENSOR_COLS 现在要包含 angular_vel ‼️\n",
        "    SENSOR_COLS = sorted([col for col in train_df.columns if any(keyword in col for keyword in [\n",
        "        'acc_', 'thm_', 'tof_', 'rot_', 'linear_', 'jerk', 'roll', 'pitch', 'yaw', 'angular_vel' # <-- 新增\n",
        "    ])])\n",
        "\n",
        "    # ‼️ 定义新的聚合特征列，这些将保存到 metadata 中 ‼️\n",
        "    AGGREGATE_COLS = [c for c in train_df.columns if 'tof_' in c and '_v' not in c] + \\\n",
        "                     [c for c in train_df.columns if 'thm_range' in c or 'thm_std' in c]\n",
        "    AGGREGATE_COLS = sorted(list(set(AGGREGATE_COLS))) # 去重并排序\n",
        "\n",
        "    print(f\"Total unique timeseries features for .npy: {len(SENSOR_COLS)}\")\n",
        "    print(f\"Total unique aggregate static features: {len(AGGREGATE_COLS)}\")\n",
        "\n",
        "\n",
        "    # 保存列名列表，供后续训练和推理使用\n",
        "    cols_path = os.path.join(CFG.PREPROCESSED_DIR, \"sensor_columns.json\")\n",
        "    with open(cols_path, 'w') as f:\n",
        "        json.dump(SENSOR_COLS, f)\n",
        "    print(f\"Saved sensor column list to {cols_path}\")\n",
        "\n",
        "    # ‼️ 5. 提取聚合特征的均值，并准备保存 .npy 文件 ‼️\n",
        "    print(\"Calculating mean of aggregate features and preparing to save .npy files...\")\n",
        "    # 计算每个序列的聚合特征的均值\n",
        "    agg_features_mean = train_df.group_by('sequence_id').agg(\n",
        "        [pl.mean(col).alias(col) for col in AGGREGATE_COLS]\n",
        "    ).sort('sequence_id')\n",
        "\n",
        "    # 将聚合特征保存到单独的文件中，以便在下一步加载\n",
        "    agg_features_path = os.path.join(CFG.PREPROCESSED_DIR, \"aggregate_features.parquet\")\n",
        "    agg_features_mean.write_parquet(agg_features_path)\n",
        "    print(f\"Saved aggregate features to {agg_features_path}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # ‼️ 新增代码块 (已修正): 计算每个序列的全局统计特征 (Mean, Std, Skew, Kurtosis) ‼️\n",
        "    # =========================================================================\n",
        "    print(\"Calculating sequence-level statistics (mean, std, skew, kurtosis)...\")\n",
        "\n",
        "    # 1. 选择要为其计算全局统计特征的列\n",
        "    cols_for_sequence_stats = [\n",
        "        'linear_acc_mag', 'rot_vel_mag', 'jerk_x', 'jerk_y', 'jerk_z',\n",
        "        'roll', 'pitch', 'yaw',\n",
        "        'tof_std_across_sensors', 'thm_range_across_sensors'\n",
        "    ]\n",
        "    cols_for_sequence_stats = [c for c in cols_for_sequence_stats if c in train_df.columns]\n",
        "    print(f\"  - Aggregating over {len(cols_for_sequence_stats)} selected core features.\")\n",
        "\n",
        "    # 2. 构建 Polars 聚合表达式 (‼️‼️ 使用正确的语法 ‼️‼️)\n",
        "    sequence_agg_exprs = []\n",
        "    for col in cols_for_sequence_stats:\n",
        "        sequence_agg_exprs.extend([\n",
        "            # 这是正确的语法: pl.col(col).aggregation_method()\n",
        "            pl.col(col).mean().alias(f'{col}_seq_mean'),\n",
        "            pl.col(col).std().alias(f'{col}_seq_std'),\n",
        "            pl.col(col).skew(bias=True).alias(f'{col}_seq_skew'),       # bias=True 匹配 pandas 的默认行为\n",
        "            pl.col(col).kurtosis(fisher=False).alias(f'{col}_seq_kurtosis') # fisher=False 得到原始峰度\n",
        "        ])\n",
        "\n",
        "    # 3. 执行聚合计算\n",
        "    sequence_stats_df = train_df.group_by('sequence_id').agg(\n",
        "        sequence_agg_exprs\n",
        "    ).sort('sequence_id').fill_null(0)\n",
        "\n",
        "    # 4. 将这些新的序列级统计特征保存到单独的文件中\n",
        "    sequence_stats_path = os.path.join(CFG.PREPROCESSED_DIR, \"sequence_stats.parquet\")\n",
        "    sequence_stats_df.write_parquet(sequence_stats_path)\n",
        "    print(f\"Saved sequence-level statistics to {sequence_stats_path}\")\n",
        "\n",
        "\n",
        "    # group_by 返回一个迭代器，我们可以直接用于并行处理\n",
        "    groups_iterator = train_df.group_by(\"sequence_id\", maintain_order=True)\n",
        "\n",
        "    Parallel(n_jobs=-1)(\n",
        "        delayed(process_and_save_group)(\n",
        "            group_df,\n",
        "            seq_id[0],\n",
        "            SENSOR_COLS,\n",
        "            CFG.PREPROCESSED_DIR,\n",
        "            CFG.TARGET_SEQ_LEN\n",
        "        ) for seq_id, group_df in tqdm(groups_iterator, desc=\"Dispatching save jobs\", total=train_df['sequence_id'].n_unique())\n",
        "    )\n",
        "\n",
        "    print(\"Pre-processing finished successfully.\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping pre-processing as RUN_PREPROCESSING is False.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "r5RPbo7OWi7s",
        "outputId": "fff15126-279f-4254-8d7d-bcf54928cb64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "eef72f2e230c4a4593cb8e7a8de9fb9f",
            "534e9c55d6d749d48d04d6de7c7a9653",
            "7b09abe413b5457b9f3d39b904d863be",
            "91443d27c8274f6f82f5ce057283104e",
            "0d214fa8511a472292f1d4c9ef6e41a9",
            "d38975a22b5c40b0b9086d0b66e8934d",
            "59674fc19b6e4643b403bdd392501ec7",
            "18e18879f8d145c4a626f213c51ce0f5",
            "c12dbbd7ee534710972601d0299e0fd1",
            "6af6aedfca4348d788650d24f00021b6",
            "1c35f7b923794dd893f0a574417a9bcd",
            "dc5e41b598bc4b2ab12295bf3f7e51d5",
            "e5d9bb8a68c64688a117053cf8736c0f",
            "1bfd2910296e4ea7ba7e4e377a3c696e",
            "440ec29047c844e08b6524f6cdcf7860",
            "c8c1c80348ce434bb07bbad6c55bccf3",
            "02a87a6f786c4d41ba736eba5ac88cfb",
            "7f0f494cc0f24e93ad54820039c28012",
            "ca5a27fff4704b868f607f373a73dee7",
            "c14e88a36ec14d65b2c34593b15b53cc",
            "3e7141ef5b9644c89c5e15e79051ddd3",
            "3c4ac08f0f6c421e8fdb2fcef6a770da"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading original CSV using Polars LazyFrame...\n",
            "Defining feature engineering steps...\n",
            "Executing vectorized feature engineering (Gravity, Euler)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-2832950027.py:134: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
            "  tof_cols = [c for c in lazy_df.columns if 'tof_' in c]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating angular velocity per sequence...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Angular Velocity:   0%|          | 0/8151 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eef72f2e230c4a4593cb8e7a8de9fb9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engineering Mag, Jerk, and Rolling features in Polars...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-2832950027.py:217: DeprecationWarning: the argument `min_periods` for `Expr.rolling_mean` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
            "  pl.col(c).rolling_mean(window_size=WINDOW_SIZE, min_periods=1).over('sequence_id').alias(f'{c}_rolling_mean_{WINDOW_SIZE}')\n",
            "/tmp/ipython-input-7-2832950027.py:220: DeprecationWarning: the argument `min_periods` for `Expr.rolling_std` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
            "  pl.col(c).rolling_std(window_size=WINDOW_SIZE, min_periods=1).over('sequence_id').alias(f'{c}_rolling_std_{WINDOW_SIZE}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering complete.\n",
            "Total unique timeseries features for .npy: 400\n",
            "Total unique aggregate static features: 24\n",
            "Saved sensor column list to /kaggle/working/preprocessed_data/sensor_columns.json\n",
            "Calculating mean of aggregate features and preparing to save .npy files...\n",
            "Saved aggregate features to /kaggle/working/preprocessed_data/aggregate_features.parquet\n",
            "Calculating sequence-level statistics (mean, std, skew, kurtosis)...\n",
            "  - Aggregating over 10 selected core features.\n",
            "Saved sequence-level statistics to /kaggle/working/preprocessed_data/sequence_stats.parquet\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dispatching save jobs:   0%|          | 0/8151 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc5e41b598bc4b2ab12295bf3f7e51d5"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell4"
      ],
      "metadata": {
        "id": "_JcoP4ghWi7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# 4. METADATA PREPARATION (USING HOLD-OUT VALIDATION)\n",
        "# ====================================================\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import joblib\n",
        "\n",
        "# 1. 加载元信息\n",
        "print(\"Preparing metadata (sequence_map)...\")\n",
        "train_df_meta = pd.read_csv(CFG.TRAIN_CSV, usecols=['sequence_id', 'subject', 'gesture'])\n",
        "train_demo = pd.read_csv(CFG.TRAIN_DEMO_CSV)\n",
        "\n",
        "# 2. 创建和处理 sequence_map\n",
        "le = LabelEncoder()\n",
        "train_df_meta['gesture_encoded'] = le.fit_transform(train_df_meta['gesture'])\n",
        "CFG.NUM_CLASSES = len(le.classes_)\n",
        "CFG.CLASS_NAMES = list(le.classes_)  # 保存类名以供参考\n",
        "\n",
        "# 创建二分类标签用于分层损失\n",
        "print(\"Creating binary target labels for hierarchical loss...\")\n",
        "TARGET_GESTURES = [\n",
        "    'Above ear - Pull hair', 'Forehead - Pull hairline', 'Forehead - Scratch',\n",
        "    'Eyebrow - Pull hair', 'Eyelash - Pull hair', 'Neck - Pinch skin',\n",
        "    'Neck - Scratch', 'Cheek - Pinch skin'\n",
        "]\n",
        "# 将手势名称映射到其编码值\n",
        "target_gesture_codes = [i for i, name in enumerate(CFG.CLASS_NAMES) if name in TARGET_GESTURES]\n",
        "print(f\"Identified {len(target_gesture_codes)} target gesture codes: {target_gesture_codes}\")\n",
        "\n",
        "sequence_map = train_df_meta[['sequence_id', 'subject', 'gesture_encoded']].drop_duplicates()\n",
        "# 添加二分类目标列 (1=目标手势, 0=非目标手势)\n",
        "sequence_map['binary_target'] = sequence_map['gesture_encoded'].isin(target_gesture_codes).astype(int)\n",
        "print(\"\\nBinary target distribution (1=Target, 0=Non-Target):\")\n",
        "print(sequence_map['binary_target'].value_counts())\n",
        "\n",
        "# 合并人口统计学信息\n",
        "sequence_map = sequence_map.merge(train_demo, on='subject', how='left')\n",
        "\n",
        "# 加载并合并聚合特征\n",
        "agg_features_path = os.path.join(CFG.PREPROCESSED_DIR, \"aggregate_features.parquet\")\n",
        "if os.path.exists(agg_features_path):\n",
        "    print(f\"\\nLoading aggregate features from {agg_features_path}...\")\n",
        "    agg_features_df = pd.read_parquet(agg_features_path)\n",
        "    sequence_map = sequence_map.merge(agg_features_df, on='sequence_id', how='left')\n",
        "    sequence_map.fillna(0, inplace=True)  # 填充缺失值\n",
        "    print(\"Aggregate features successfully merged.\")\n",
        "else:\n",
        "    print(\"Warning: Aggregate features file not found. Skipping merge.\")\n",
        "\n",
        "# 处理人口统计学特征中的空值\n",
        "for col in ['height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']:\n",
        "    if col in sequence_map.columns:\n",
        "        sequence_map[col].fillna(sequence_map[col].mean(), inplace=True)\n",
        "\n",
        "# 计算新的特征比率\n",
        "sequence_map['height_cm_safe'] = sequence_map['height_cm'].replace(0, 1e-6)\n",
        "sequence_map['shoulder_wrist_ratio'] = sequence_map['shoulder_to_wrist_cm'] / sequence_map['height_cm_safe']\n",
        "sequence_map['elbow_wrist_ratio'] = sequence_map['elbow_to_wrist_cm'] / sequence_map['height_cm_safe']\n",
        "sequence_map.drop('height_cm_safe', axis=1, inplace=True)\n",
        "\n",
        "# 更新 CFG.DEMO_COLS 以包含聚合特征\n",
        "AGGREGATE_COLS = sorted([\n",
        "    c for c in sequence_map.columns\n",
        "    if ('tof_' in c and '_v' not in c) or ('thm_range' in c or 'thm_std' in c)\n",
        "])\n",
        "CFG.ALL_STATIC_COLS = CFG.DEMO_COLS + AGGREGATE_COLS\n",
        "print(f\"Total static features (demographics + aggregates): {len(CFG.ALL_STATIC_COLS)}\")\n",
        "\n",
        "# 标准化数值列\n",
        "scaler = StandardScaler()\n",
        "numerical_static_cols = [\n",
        "    col for col in CFG.ALL_STATIC_COLS\n",
        "    if col in sequence_map.columns and sequence_map[col].dtype in ['int64', 'float64']\n",
        "]\n",
        "if numerical_static_cols:\n",
        "    sequence_map[numerical_static_cols] = scaler.fit_transform(sequence_map[numerical_static_cols])\n",
        "    print(f\"Saving scaler for columns: {numerical_static_cols}\")\n",
        "    os.makedirs(CFG.MODEL_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    # 保存标准化器\n",
        "    scaler_path = os.path.join(CFG.MODEL_OUTPUT_DIR, \"min_max_scaler.joblib\")\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "    print(f\"Scaler successfully saved to: {scaler_path}\")\n",
        "\n",
        "    # 保存标准化的列名\n",
        "    scaler_cols_path = os.path.join(CFG.MODEL_OUTPUT_DIR, \"scaler_columns.json\")\n",
        "    with open(scaler_cols_path, 'w') as f:\n",
        "        json.dump(numerical_static_cols, f)\n",
        "    print(f\"Scaler columns saved to: {scaler_cols_path}\")\n",
        "\n",
        "# 计算类别权重以处理类别不平衡\n",
        "print(\"\\nCalculating class weights to handle imbalance...\")\n",
        "class_labels = np.unique(sequence_map['gesture_encoded'])\n",
        "class_weights_array = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=class_labels,\n",
        "    y=sequence_map['gesture_encoded'].values\n",
        ")\n",
        "CLASS_WEIGHTS = torch.tensor(class_weights_array, dtype=torch.float32).to(CFG.DEVICE)\n",
        "print(f\"Class weights calculated and moved to {CFG.DEVICE}.\")\n",
        "print(f\"Weights: {CLASS_WEIGHTS}\")\n",
        "\n",
        "# 创建 K-Fold 分割\n",
        "print(f\"\\nCreating {CFG.N_FOLDS}-fold splits, grouped by subject and stratified by gesture...\")\n",
        "skf = StratifiedGroupKFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=42)\n",
        "sequence_map['fold'] = -1\n",
        "for fold_num, (train_idx, val_idx) in enumerate(skf.split(sequence_map, sequence_map['gesture_encoded'], sequence_map['subject'])):\n",
        "    sequence_map.loc[val_idx, 'fold'] = fold_num\n",
        "\n",
        "# 打印分割分布\n",
        "print(\"Fold distribution:\")\n",
        "print(sequence_map['fold'].value_counts())\n",
        "assert (sequence_map['fold'] == -1).sum() == 0, \"Some sequences were not assigned a fold!\""
      ],
      "metadata": {
        "trusted": true,
        "id": "6_iazgeDWi7v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CELL 5"
      ],
      "metadata": {
        "id": "HEpcRKIMWi7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# CELL 5: LEARNING RATE FINDER (ADAPTED FOR HIERARCHICAL LOSS)\n",
        "# ====================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "class LRFinder:\n",
        "    \"\"\"\n",
        "    一个适配了分层损失的学习率范围测试器。\n",
        "    \"\"\"\n",
        "    def __init__(self, model, optimizer, criterion_18_class, criterion_binary, loss_alpha, device):\n",
        "        \"\"\"\n",
        "        初始化学习率范围测试器。\n",
        "\n",
        "        Args:\n",
        "            model: 你的 PyTorch 模型。\n",
        "            optimizer: 你的优化器。\n",
        "            criterion_18_class: 用于18分类任务的损失函数。\n",
        "            criterion_binary: 用于二分类任务的损失函数。\n",
        "            loss_alpha (float): 二分类损失的权重。\n",
        "            device: 'cuda' 或 'cpu'。\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion_18_class = criterion_18_class\n",
        "        self.criterion_binary = criterion_binary\n",
        "        self.loss_alpha = loss_alpha\n",
        "        self.device = device\n",
        "        self.history = {\"lr\": [], \"loss\": []}\n",
        "\n",
        "        # 保存模型初始状态，以便测试后恢复\n",
        "        torch.save(model.state_dict(), 'lr_finder_initial_state.pth')\n",
        "\n",
        "    def range_test(self, train_loader, start_lr=1e-7, end_lr=1, num_iter=100, beta=0.98):\n",
        "        \"\"\"\n",
        "        执行学习率范围测试。\n",
        "\n",
        "        Args:\n",
        "            train_loader: 训练数据加载器。\n",
        "            start_lr (float): 起始学习率。\n",
        "            end_lr (float): 结束学习率。\n",
        "            num_iter (int): 测试的迭代次数。\n",
        "            beta (float): 平滑参数。\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        lr_scheduler = LRScheduler(self.optimizer, start_lr, end_lr, num_iter)\n",
        "        avg_loss = 0.0\n",
        "\n",
        "        data_iter = iter(train_loader)\n",
        "        pbar = tqdm(range(num_iter), desc=\"LR Range Test (Hierarchical Loss)\")\n",
        "\n",
        "        for i in pbar:\n",
        "            try:\n",
        "                # 解包5个项目\n",
        "                imu, thermo, static, labels_18, labels_binary = next(data_iter)\n",
        "            except StopIteration:\n",
        "                data_iter = iter(train_loader)\n",
        "                imu, thermo, static, labels_18, labels_binary = next(data_iter)\n",
        "\n",
        "            # 将数据移动到设备\n",
        "            imu, thermo, static, labels_18, labels_binary = (\n",
        "                imu.to(self.device),\n",
        "                thermo.to(self.device),\n",
        "                static.to(self.device),\n",
        "                labels_18.to(self.device),\n",
        "                labels_binary.to(self.device)\n",
        "            )\n",
        "\n",
        "            # 前向传播，模型返回两组输出\n",
        "            outputs_18, outputs_binary = self.model(imu, thermo, static)\n",
        "            outputs_18_float = outputs_18_half.float()\n",
        "            outputs_binary_float = outputs_binary_half.float()\n",
        "\n",
        "            # 计算分层组合损失\n",
        "            loss18 = self.criterion_18_class(outputs_18_float, labels_18)\n",
        "            loss2 = self.criterion_binary(outputs_binary_float, labels_binary)\n",
        "            loss = (1 - self.loss_alpha) * loss18 + self.loss_alpha * loss2\n",
        "\n",
        "            # 计算平滑损失\n",
        "            avg_loss = beta * avg_loss + (1 - beta) * loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**(i + 1))\n",
        "\n",
        "            self.history[\"lr\"].append(lr_scheduler.get_lr()[0])\n",
        "            self.history[\"loss\"].append(smoothed_loss)\n",
        "\n",
        "            pbar.set_postfix(loss=smoothed_loss, lr=lr_scheduler.get_lr()[0])\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            if i > 0 and smoothed_loss > 4 * self.history[\"loss\"][0]:\n",
        "                print(\"\\nLoss diverged. Stopping early.\")\n",
        "                break\n",
        "\n",
        "        print(\"\\nLR Range Test Finished.\")\n",
        "\n",
        "    def plot(self, skip_start=10, skip_end=5, suggestion=None):\n",
        "        \"\"\"\n",
        "        绘制学习率范围测试结果。\n",
        "\n",
        "        Args:\n",
        "            skip_start (int): 跳过开始的若干点。\n",
        "            skip_end (int): 跳过结尾的若干点。\n",
        "            suggestion (float): 建议的学习率（可选）。\n",
        "        \"\"\"\n",
        "        if not self.history[\"lr\"]:\n",
        "            print(\"No history to plot. Please run range_test first.\")\n",
        "            return\n",
        "\n",
        "        lrs = self.history[\"lr\"][skip_start:-skip_end]\n",
        "        losses = self.history[\"loss\"][skip_start:-skip_end]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(lrs, losses)\n",
        "        if suggestion:\n",
        "            plt.axvline(x=suggestion, color='r', linestyle='--', label=f'Suggested LR: {suggestion:.2e}')\n",
        "            plt.legend()\n",
        "        plt.xscale(\"log\")\n",
        "        plt.xlabel(\"Learning Rate (log scale)\")\n",
        "        plt.ylabel(\"Combined Loss\")\n",
        "        plt.title(\"Learning Rate Range Test\")\n",
        "        plt.grid(True, which=\"both\", ls=\"--\")\n",
        "        plt.show()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        恢复模型到其初始状态。\n",
        "        \"\"\"\n",
        "        self.model.load_state_dict(torch.load('lr_finder_initial_state.pth'))\n",
        "        print(\"Model state has been reset to its initial state.\")\n",
        "\n",
        "    def suggestion(self, skip_start=10, skip_end=5):\n",
        "        \"\"\"\n",
        "        根据梯度变化建议学习率。\n",
        "\n",
        "        Args:\n",
        "            skip_start (int): 跳过开始的若干点。\n",
        "            skip_end (int): 跳过结尾的若干点。\n",
        "\n",
        "        Returns:\n",
        "            float: 建议的学习率，若无建议则返回 None。\n",
        "        \"\"\"\n",
        "        if not self.history[\"lr\"] or len(self.history[\"lr\"]) < skip_start + skip_end + 2:\n",
        "            print(\"Not enough history to suggest a learning rate.\")\n",
        "            return None\n",
        "\n",
        "        lrs = self.history[\"lr\"][skip_start:-skip_end]\n",
        "        losses = self.history[\"loss\"][skip_start:-skip_end]\n",
        "        log_lrs = np.log10(lrs)\n",
        "        gradients = np.gradient(losses, log_lrs)\n",
        "        min_grad_idx = np.argmin(gradients)\n",
        "        return lrs[min_grad_idx]\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# LRScheduler 类 (保持不变)\n",
        "# ====================================================\n",
        "\n",
        "class LRScheduler:\n",
        "    \"\"\"\n",
        "    学习率调度器，用于线性或指数增加学习率。\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, start_lr, end_lr, num_iter):\n",
        "        self.optimizer = optimizer\n",
        "        self.start_lr = start_lr\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        self.iter = 0\n",
        "        self.factor = (end_lr / start_lr) ** (1 / (num_iter - 1))\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        更新当前学习率。\n",
        "        \"\"\"\n",
        "        self.iter += 1\n",
        "        lr = self.start_lr * (self.factor ** self.iter)\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def get_lr(self):\n",
        "        \"\"\"\n",
        "        获取当前学习率。\n",
        "        \"\"\"\n",
        "        return [param_group['lr'] for param_group in self.optimizer.param_groups]"
      ],
      "metadata": {
        "trusted": true,
        "id": "ArfUdaudWi7y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================='\n",
        "# CELL 7: DATASET AND MODEL DEFINITION (ADVANCED DUAL-TOWER)\n",
        "# ===================================================='\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# ===================================================='\n",
        "# 完整的、优化后的 Dataset 类\n",
        "# ===================================================='\n",
        "\n",
        "class DualTowerDataset(Dataset):\n",
        "    \"\"\"\n",
        "    一个高效的数据集类，它加载预处理好的 .npy 文件。\n",
        "    ‼️ 已修改: 返回18分类和二分类两种标签，用于分层损失。\n",
        "    \"\"\"\n",
        "    def __init__(self, df_map, all_sensor_cols, static_cols=None, preprocessed_dir=CFG.PREPROCESSED_DIR, is_train=False):\n",
        "        self.df_map = df_map.reset_index(drop=True)\n",
        "        self.static_cols = static_cols\n",
        "        self.preprocessed_dir = preprocessed_dir\n",
        "        self.is_train = is_train\n",
        "\n",
        "        imu_keywords = ['acc_', 'rot_', 'linear_', 'jerk', 'roll', 'pitch', 'yaw', 'angular_vel']\n",
        "        self.imu_indices = [i for i, col in enumerate(all_sensor_cols) if any(keyword in col for keyword in imu_keywords)]\n",
        "\n",
        "        all_indices_set = set(range(len(all_sensor_cols)))\n",
        "        self.thermo_tof_indices = sorted(list(all_indices_set - set(self.imu_indices)))\n",
        "\n",
        "        self.num_imu_channels = len(self.imu_indices)\n",
        "        self.num_thermo_tof_channels = len(self.thermo_tof_indices)\n",
        "\n",
        "        print(f\"Dataset created. Mode: {'Train' if is_train else 'Validation'}.\")\n",
        "        print(f\"  - IMU Tower Channels: {self.num_imu_channels}\")\n",
        "        print(f\"  - Thermo/ToF Tower Channels: {self.num_thermo_tof_channels}\")\n",
        "        assert (self.num_imu_channels + self.num_thermo_tof_channels) == len(all_sensor_cols), \"Mismatch in total channels!\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_map)\n",
        "\n",
        "    def _apply_augmentations(self, data_array):\n",
        "        if np.random.rand() < 0.3:\n",
        "            data_array += np.random.normal(0, 0.01, data_array.shape)\n",
        "        if np.random.rand() < 0.3:\n",
        "            data_array *= np.random.uniform(0.9, 1.1)\n",
        "        if np.random.rand() < 0.3:\n",
        "            max_shift = int(data_array.shape[1] * 0.1)\n",
        "            shift_amount = np.random.randint(-max_shift, max_shift + 1)\n",
        "            if shift_amount != 0:\n",
        "                data_array = np.roll(data_array, shift_amount, axis=1)\n",
        "        return data_array\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq_info = self.df_map.iloc[idx]\n",
        "        seq_id = seq_info['sequence_id']\n",
        "        # ‼️ 修改: 获取18分类和二分类两种标签\n",
        "        label_18 = seq_info['gesture_encoded']\n",
        "        label_binary = seq_info['binary_target']\n",
        "\n",
        "        file_path = os.path.join(self.preprocessed_dir, f\"{seq_id}.npy\")\n",
        "        ts_data = np.load(file_path)\n",
        "\n",
        "        imu_data = ts_data[self.imu_indices, :]\n",
        "        thermo_tof_data = ts_data[self.thermo_tof_indices, :]\n",
        "\n",
        "        if self.is_train:\n",
        "            if np.random.rand() < 0.5:\n",
        "                thermo_tof_data = np.zeros_like(thermo_tof_data)\n",
        "            imu_data = self._apply_augmentations(imu_data)\n",
        "\n",
        "        imu_tensor = torch.tensor(imu_data, dtype=torch.float32)\n",
        "        thermo_tof_tensor = torch.tensor(thermo_tof_data, dtype=torch.float32)\n",
        "        static_features = torch.tensor(seq_info[self.static_cols].values.astype(np.float32), dtype=torch.float32)\n",
        "\n",
        "        # ‼️ 修改: 将两种标签都转换为Tensor并返回\n",
        "        return imu_tensor, thermo_tof_tensor, static_features, torch.tensor(label_18, dtype=torch.long), torch.tensor(label_binary, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ====================================================\n",
        "# CELL 1: CORE BUILDING BLOCKS (Largely unchanged, but with docstrings)\n",
        "# ====================================================\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation Module for 1D convolutions.\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEModule, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class ResidualBlockSE(nn.Module):\n",
        "    \"\"\"Residual Block with a Squeeze-and-Excitation module.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, downsample=None):\n",
        "        super(ResidualBlockSE, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=(kernel_size - 1) // 2, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding=(kernel_size - 1) // 2, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.se = SEModule(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.se(out)\n",
        "        out += identity\n",
        "        return self.relu(out)\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    \"\"\"Generalized Mean Pooling.\"\"\"\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.avg_pool1d(x.clamp(min=self.eps).pow(self.p), x.size(-1)).pow(1./self.p)\n",
        "\n",
        "# ====================================================\n",
        "# CELL 2: CONFORMER BLOCKS (Central component of the new tower)\n",
        "# ====================================================\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    \"\"\"Swish activation function.\"\"\"\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "class Transpose(nn.Module):\n",
        "    \"\"\"A simple layer to transpose dimensions.\"\"\"\n",
        "    def __init__(self, dim0, dim1):\n",
        "        super().__init__()\n",
        "        self.dim0, self.dim1 = dim0, dim1\n",
        "    def forward(self, x):\n",
        "        return x.transpose(self.dim0, self.dim1)\n",
        "\n",
        "class FeedForwardModule(nn.Module):\n",
        "    \"\"\"Feed-Forward Network module from the Conformer paper.\"\"\"\n",
        "    def __init__(self, d_model, expansion_factor=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, d_model * expansion_factor),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model * expansion_factor, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sequential(x)\n",
        "\n",
        "class ConvolutionModule(nn.Module):\n",
        "    \"\"\"Convolutional module from the Conformer paper.\"\"\"\n",
        "    def __init__(self, d_model, kernel_size=31, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert kernel_size % 2 == 1, \"Convolution kernel size must be odd.\"\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            Transpose(1, 2),  # (B, L, C) -> (B, C, L)\n",
        "            nn.Conv1d(d_model, 2 * d_model, kernel_size=1, stride=1, padding=0),\n",
        "            nn.GLU(dim=1),\n",
        "            nn.Conv1d(d_model, d_model, kernel_size, stride=1, padding=(kernel_size - 1)//2, groups=d_model),\n",
        "            nn.BatchNorm1d(d_model),\n",
        "            Swish(),\n",
        "            nn.Conv1d(d_model, d_model, kernel_size=1, stride=1, padding=0),\n",
        "            nn.Dropout(dropout),\n",
        "            Transpose(1, 2)  # (B, C, L) -> (B, L, C)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sequential(x)\n",
        "\n",
        "class ConformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    The full Conformer block, following the structure: FFN -> Attention -> Conv -> FFN.\n",
        "    Each connection is residual.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_head, ffn_expansion_factor=4, conv_kernel_size=31, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ffn1 = FeedForwardModule(d_model, ffn_expansion_factor, dropout)\n",
        "        self.attention_norm = nn.LayerNorm(d_model)\n",
        "        self.attention = nn.MultiheadAttention(d_model, n_head, dropout=dropout, batch_first=True)\n",
        "        self.attention_dropout = nn.Dropout(dropout)\n",
        "        self.conv_module = ConvolutionModule(d_model, conv_kernel_size, dropout)\n",
        "        self.ffn2 = FeedForwardModule(d_model, ffn_expansion_factor, dropout)\n",
        "        self.final_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x shape: (batch, seq_len, d_model)\n",
        "        x = x + 0.5 * self.ffn1(x)\n",
        "        residual = x\n",
        "        x = self.attention_norm(x)\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        x = residual + self.attention_dropout(attn_output)\n",
        "        x = x + self.conv_module(x)\n",
        "        x = x + 0.5 * self.ffn2(x)\n",
        "        x = self.final_norm(x)\n",
        "        return x\n",
        "\n",
        "# =========================================================\n",
        "# CELL 3: OPTIMIZED SENSOR TOWER AND FUSION\n",
        "# =========================================================\n",
        "\n",
        "class SensorConformerTower(nn.Module):\n",
        "    \"\"\"\n",
        "    OPTIMIZED: A generic and configurable tower for time-series sensor data.\n",
        "    It uses a deep CNN backbone for downsampling and local feature extraction,\n",
        "    followed by a stack of Conformer blocks to model long-range dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, embed_dim=192, cnn_depth=2, n_layers=4, n_head=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # --- Deep CNN Backbone ---\n",
        "        layers = []\n",
        "        # Initial convolution layer\n",
        "        layers.extend([\n",
        "            nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        ])\n",
        "\n",
        "        # Stack of residual blocks\n",
        "        current_channels = 64\n",
        "        for i in range(cnn_depth):\n",
        "            # Downsample on the first block\n",
        "            stride = 2 if i == 0 else 1\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv1d(current_channels, embed_dim, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm1d(embed_dim)\n",
        "            ) if i == 0 or current_channels != embed_dim else None\n",
        "\n",
        "            layers.append(ResidualBlockSE(\n",
        "                current_channels, embed_dim, kernel_size=3, stride=stride, downsample=downsample\n",
        "            ))\n",
        "            current_channels = embed_dim\n",
        "\n",
        "        self.backbone = nn.Sequential(*layers)\n",
        "\n",
        "        # --- Conformer Encoder ---\n",
        "        self.conformer_encoder = nn.Sequential(\n",
        "            *[ConformerBlock(d_model=embed_dim, n_head=n_head, dropout=dropout) for _ in range(n_layers)]\n",
        "        )\n",
        "\n",
        "        self.pooling = GeM()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input x: (Batch, Channels, TimeSteps)\n",
        "        \"\"\"\n",
        "        # 1. CNN Backbone for local features and downsampling\n",
        "        x = self.backbone(x)  # -> (B, embed_dim, L_out)\n",
        "\n",
        "        # 2. Reshape for Conformer: (B, C, L) -> (B, L, C)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # 3. Conformer for global context\n",
        "        x = self.conformer_encoder(x)  # -> (B, L_out, embed_dim)\n",
        "\n",
        "        # 4. Reshape for pooling: (B, L, C) -> (B, C, L)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # 5. Pool and flatten to get a fixed-size vector\n",
        "        x = self.pooling(x)    # -> (B, embed_dim, 1)\n",
        "        x = self.flatten(x)    # -> (B, embed_dim)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class EnhancedFusionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    OPTIMIZED: A more powerful fusion block that allows for rich, non-linear\n",
        "    interaction between the features from different modalities.\n",
        "    \"\"\"\n",
        "    def __init__(self, combined_dim, hidden_dim_multiplier=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        hidden_dim = combined_dim * hidden_dim_multiplier\n",
        "        self.fusion_net = nn.Sequential(\n",
        "            nn.LayerNorm(combined_dim),\n",
        "            nn.Linear(combined_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, combined_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, combined_features):\n",
        "        # The residual connection is crucial for stable training\n",
        "        return combined_features + self.fusion_net(combined_features)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# CELL 4: FINAL OPTIMIZED MODEL\n",
        "# =========================================================\n",
        "\n",
        "class OptimizedDualTowerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    OPTIMIZED main model with architectural symmetry, enhanced fusion, and better configuration.\n",
        "\n",
        "    This model has a shared backbone and two separate classifier heads for hierarchical loss.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 num_imu_channels: int,\n",
        "                 num_thermo_tof_channels: int,\n",
        "                 num_static_features: int,\n",
        "                 num_classes: int,\n",
        "                 # --- Model Configuration ---\n",
        "                 embed_dim: int = 192,\n",
        "                 cnn_depth: int = 2,\n",
        "                 n_layers_conformer: int = 4,\n",
        "                 n_head: int = 4,\n",
        "                 dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        # --- Tower 1: IMU Sensor Data ---\n",
        "        self.imu_tower = SensorConformerTower(\n",
        "            in_channels=num_imu_channels,\n",
        "            embed_dim=embed_dim,\n",
        "            cnn_depth=cnn_depth,\n",
        "            n_layers=n_layers_conformer,\n",
        "            n_head=n_head,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # --- Tower 2: Thermo/ToF Sensor Data (Symmetric Architecture) ---\n",
        "        self.thermo_tof_tower = SensorConformerTower(\n",
        "            in_channels=num_thermo_tof_channels,\n",
        "            embed_dim=embed_dim,\n",
        "            cnn_depth=cnn_depth,\n",
        "            n_layers=n_layers_conformer,\n",
        "            n_head=n_head,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # --- Fusion and Classification ---\n",
        "        combined_dim = embed_dim + embed_dim + num_static_features\n",
        "\n",
        "        # Use the new, more powerful fusion block\n",
        "        self.fusion_block = EnhancedFusionBlock(combined_dim, dropout=dropout)\n",
        "\n",
        "        # Shared classifier backbone\n",
        "        self.classifier_backbone = nn.Sequential(\n",
        "            nn.LayerNorm(combined_dim), # Use LayerNorm for batch-independence\n",
        "            nn.Linear(combined_dim, 512),\n",
        "            nn.GELU(), # GELU is often a good alternative to ReLU\n",
        "            nn.Dropout(0.3) # Slightly higher dropout before final layers\n",
        "        )\n",
        "\n",
        "        # Heads for hierarchical loss\n",
        "        self.classifier_18_class = nn.Linear(512, num_classes)\n",
        "        self.classifier_binary = nn.Linear(512, 2)\n",
        "\n",
        "    def forward(self, imu_data, thermo_tof_data, static_features):\n",
        "        # 1. Process each modality through its dedicated tower\n",
        "        imu_features = self.imu_tower(imu_data)             # (B, embed_dim)\n",
        "        thermo_tof_features = self.thermo_tof_tower(thermo_tof_data) # (B, embed_dim)\n",
        "\n",
        "        # 2. Combine features from all sources\n",
        "        # Ensure static_features is (B, num_static_features)\n",
        "        combined_features = torch.cat([imu_features, thermo_tof_features, static_features], dim=1)\n",
        "\n",
        "        # 3. Fuse the combined features with the enhanced block\n",
        "        fused_features = self.fusion_block(combined_features)\n",
        "\n",
        "        # 4. Pass through shared classifier backbone and then to heads\n",
        "        shared_output = self.classifier_backbone(fused_features)\n",
        "        logits_18_class = self.classifier_18_class(shared_output)\n",
        "        logits_binary = self.classifier_binary(shared_output)\n",
        "\n",
        "        return logits_18_class, logits_binary"
      ],
      "metadata": {
        "trusted": true,
        "id": "aAs1LkK6Wi7z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CELL 6"
      ],
      "metadata": {
        "id": "oqA23D08Wi8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# 6. TRAINING LOOP (SIMPLIFIED & ADAPTED)\n",
        "# ====================================================\n",
        "\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "\n",
        "def load_preprocessed_sensor_cols(cfg):\n",
        "    \"\"\"\n",
        "    加载工程化的传感器列列表。\n",
        "    \"\"\"\n",
        "    cols_path = os.path.join(cfg.PREPROCESSED_DIR, \"sensor_columns.json\")\n",
        "    if not os.path.exists(cols_path):\n",
        "        raise FileNotFoundError(f\"关键产物文件未找到: {cols_path}。请先运行预处理。\")\n",
        "    print(f\"从 {cols_path} 加载权威的传感器列列表...\")\n",
        "    with open(cols_path, 'r') as f:\n",
        "        sensor_cols = json.load(f)\n",
        "    print(f\"成功加载 {len(sensor_cols)} 个工程化特征列。\")\n",
        "    return sensor_cols\n",
        "\n",
        "\n",
        "try:\n",
        "    ALL_SENSOR_COLS = load_preprocessed_sensor_cols(CFG)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"错误: {e}\")\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# EarlyStopping Class (保持不变)\n",
        "# ====================================================\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    用于检测验证集性能的早停机制。\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=5, verbose=False, delta=0, path='best_model.pth', trace_func=print, mode='max'):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_metric_best = np.Inf if mode == 'min' else -np.Inf\n",
        "        self.delta = delta if mode == 'max' else -delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "        self.mode = mode\n",
        "\n",
        "    def __call__(self, val_metric, model):\n",
        "        score = val_metric if self.mode == 'max' else -val_metric\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_metric, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "            self.save_checkpoint(val_metric, model)\n",
        "\n",
        "    def save_checkpoint(self, val_metric, model):\n",
        "        \"\"\"\n",
        "        保存验证集性能最优的模型。\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation metric improved ({self.val_metric_best:.6f} --> {val_metric:.6f}). Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_metric_best = val_metric\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z0inU4HoWi8G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练loop"
      ],
      "metadata": {
        "id": "_XBChuhtWi8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Training Loop\n",
        "# ====================================================\n",
        "\n",
        "from accelerate import Accelerator\n",
        "\n",
        "# =========================================================================\n",
        "# ‼️ 新增: Mixup 辅助函数 ‼️\n",
        "# =========================================================================\n",
        "\n",
        "def mixup_data(x_imu, x_thermo, x_static, y_18, y_binary, alpha=0.5, device='cuda'):\n",
        "    \"\"\"返回 mixed inputs, a, b, 和 lambda.\"\"\"\n",
        "    if alpha > 0:\n",
        "        # lam 是 beta 分布的采样，决定混合比例\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x_imu.size()[0]\n",
        "    # 生成随机的索引，用于将当前 batch 内的样本进行混合\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    # 混合输入数据\n",
        "    mixed_x_imu = lam * x_imu + (1 - lam) * x_imu[index, :]\n",
        "    mixed_x_thermo = lam * x_thermo + (1 - lam) * x_thermo[index, :]\n",
        "    mixed_x_static = lam * x_static + (1 - lam) * x_static[index, :]\n",
        "\n",
        "    # 获取原始标签和被混合的标签\n",
        "    y_18_a, y_18_b = y_18, y_18[index]\n",
        "    y_binary_a, y_binary_b = y_binary, y_binary[index]\n",
        "\n",
        "    return mixed_x_imu, mixed_x_thermo, mixed_x_static, y_18_a, y_18_b, y_binary_a, y_binary_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    \"\"\"计算 Mixup 的损失\"\"\"\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# --- 定义常量 ---\n",
        "MIXUP_ALPHA = 0.5 # 现在我们将真正使用它\n",
        "\n",
        "def train_model(fold: int, accelerator: Accelerator):\n",
        "    accelerator.print(f\"========== STARTING TRAINING FOR FOLD {fold} (with Mixup) ==========\")\n",
        "\n",
        "    # 数据集划分和加载器 (这部分逻辑不变)\n",
        "    train_map = sequence_map[sequence_map['fold'] != fold].reset_index(drop=True)\n",
        "    val_map = sequence_map[sequence_map['fold'] == fold].reset_index(drop=True)\n",
        "    train_dataset = DualTowerDataset(train_map, all_sensor_cols=ALL_SENSOR_COLS, static_cols=CFG.ALL_STATIC_COLS, is_train=True)\n",
        "    val_dataset = DualTowerDataset(val_map, all_sensor_cols=ALL_SENSOR_COLS, static_cols=CFG.ALL_STATIC_COLS, is_train=False)\n",
        "\n",
        "    # WeightedRandomSampler (这部分逻辑不变)\n",
        "    train_targets = torch.tensor(train_dataset.df_map['gesture_encoded'].values)\n",
        "    class_counts = torch.bincount(train_targets)\n",
        "    class_weights = 1. / class_counts.float()\n",
        "    sample_weights = torch.tensor([class_weights[t] for t in train_targets])\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, sampler=sampler, shuffle=False, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # 模型、优化器、调度器 (这部分逻辑不变)\n",
        "    model = OptimizedDualTowerModel(num_imu_channels=train_dataset.num_imu_channels,\n",
        "        num_thermo_tof_channels=train_dataset.num_thermo_tof_channels,\n",
        "        num_static_features=len(CFG.ALL_STATIC_COLS),\n",
        "        num_classes=CFG.NUM_CLASSES,\n",
        "        embed_dim=200,\n",
        "        cnn_depth=3,\n",
        "        n_layers_conformer=2,\n",
        "        n_head=4,\n",
        "        dropout=0.3)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.LEARNING_RATE)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=CFG.LEARNING_RATE,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=CFG.EPOCHS,\n",
        "        pct_start=0.2\n",
        "    )\n",
        "\n",
        "\n",
        "    # Accelerate 准备\n",
        "    model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(model, optimizer, train_loader, val_loader, scheduler)\n",
        "\n",
        "    # 损失函数\n",
        "    criterion_18_class = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    criterion_binary = nn.CrossEntropyLoss()\n",
        "\n",
        "    # ====================================================\n",
        "    # 优化的 LR FINDER 调用部分 (默认注释，需要时取消注释)\n",
        "    # ====================================================\n",
        "\n",
        "    # print(\"--- Starting Learning Rate Finder ---\")\n",
        "\n",
        "    # # 初始化 LRFinder，传入模型、优化器、损失函数和 alpha 参数\n",
        "    # lr_finder = LRFinder(\n",
        "    #     model,\n",
        "    #     optimizer,\n",
        "    #     criterion_18_class,\n",
        "    #     criterion_binary,\n",
        "    #     CFG.HIERARCHICAL_LOSS_ALPHA,\n",
        "    #     device=CFG.DEVICE\n",
        "    # )\n",
        "\n",
        "    # # 执行学习率范围测试\n",
        "    # lr_finder.range_test(train_loader, start_lr=1e-8, end_lr=10, num_iter=300)\n",
        "\n",
        "    # # 绘制测试结果并获取建议的学习率\n",
        "    # suggestion = lr_finder.suggestion()\n",
        "    # print(f\"Suggested LR: {suggestion}\")\n",
        "    # lr_finder.plot(skip_start=10, skip_end=5, suggestion=suggestion)\n",
        "\n",
        "    # # 重置模型和优化器，准备正式训练\n",
        "    # lr_finder.reset()\n",
        "    # print(\"--- LR Finder Finished. Ready for main training. ---\")\n",
        "\n",
        "    # # 如果仅运行学习率测试，可以直接退出，避免执行后续训练\n",
        "    # return [] , []\n",
        "\n",
        "\n",
        "    # 模型保存和早停设置\n",
        "    model_path = f\"{CFG.MODEL_OUTPUT_DIR}/best_model_fold_{fold}.pth\"\n",
        "    early_stopping = EarlyStopping(patience=30, verbose=accelerator.is_main_process, path=model_path, mode='min')\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    for epoch in range(CFG.EPOCHS):\n",
        "        model.train()\n",
        "\n",
        "        epoch_total_loss = 0.0\n",
        "\n",
        "        # 使用tqdm时，通过 accelerator.is_main_process 禁用非主进程的进度条\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{CFG.EPOCHS} [Training]\", disable=not accelerator.is_main_process)\n",
        "\n",
        "        for i, (imu_data, thermo_tof_data, statics, labels_18, labels_binary) in enumerate(pbar):\n",
        "            # ‼️ 数据已经自动移动到正确设备，无需手动 .to(device) ‼️\n",
        "\n",
        "            # ‼️ 移除 torch.amp.autocast, Accelerate 会自动处理 ‼️\n",
        "            outputs_18, outputs_binary = model(imu_data, thermo_tof_data, statics)\n",
        "\n",
        "            # 在混合精度下，损失计算也应在 autocast 上下文中\n",
        "            # 但由于模型输出已经是 fp16/bf16, 需要转回 fp32 计算损失\n",
        "            loss_18_class = criterion_18_class(outputs_18.float(), labels_18)\n",
        "            loss_binary_class = criterion_binary(outputs_binary.float(), labels_binary)\n",
        "            loss = (1 - CFG.HIERARCHICAL_LOSS_ALPHA) * loss_18_class + CFG.HIERARCHICAL_LOSS_ALPHA * loss_binary_class\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # ‼️ 使用 accelerator.backward(loss) 代替 loss.backward() ‼️\n",
        "            # 它会自动处理梯度缩放 (GradScaler)\n",
        "            accelerator.backward(loss)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            epoch_total_loss += loss.item()\n",
        "\n",
        "            if accelerator.is_main_process:\n",
        "                pbar.set_postfix({\n",
        "                    'loss': epoch_total_loss / (i + 1),\n",
        "                    'lr': scheduler.get_last_lr()[0]\n",
        "                })\n",
        "\n",
        "        # --- 验证循环 ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_labels, all_preds = [], []\n",
        "\n",
        "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{CFG.EPOCHS} [Validation]\", disable=not accelerator.is_main_process)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imu_data, thermo_tof_data, statics, labels_18, labels_binary in val_pbar:\n",
        "                outputs_18, outputs_binary = model(imu_data, thermo_tof_data, statics)\n",
        "\n",
        "                loss_18_class = criterion_18_class(outputs_18.float(), labels_18)\n",
        "                loss_binary_class = criterion_binary(outputs_binary.float(), labels_binary)\n",
        "                loss = (1 - CFG.HIERARCHICAL_LOSS_ALPHA) * loss_18_class + CFG.HIERARCHICAL_LOSS_ALPHA * loss_binary_class\n",
        "                val_loss += loss.item() * imu_data.size(0)\n",
        "\n",
        "                preds = torch.argmax(outputs_18, dim=1)\n",
        "\n",
        "                # ‼️ 关键: 使用 accelerator.gather_for_metrics ‼️\n",
        "                # 在分布式环境中，这会从所有进程收集张量，确保评估在整个验证集上进行\n",
        "                gathered_preds = accelerator.gather_for_metrics(preds)\n",
        "                gathered_labels = accelerator.gather_for_metrics(labels_18)\n",
        "\n",
        "                all_preds.append(gathered_preds.cpu())\n",
        "                all_labels.append(gathered_labels.cpu())\n",
        "\n",
        "        # 在循环外拼接所有批次的张量\n",
        "        all_preds = torch.cat(all_preds).numpy()\n",
        "        all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
        "        val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "        # 只在主进程打印指标和执行早停/保存\n",
        "        if accelerator.is_main_process:\n",
        "            accelerator.print(f\"Epoch {epoch + 1}, Val Loss: {avg_val_loss:.6f}, Val Accuracy: {val_accuracy:.6f}, Val Macro F1: {val_f1:.4f}\")\n",
        "\n",
        "            # ‼️ 保存模型时，先用 unwrap_model 获取原始的PyTorch模型 ‼️\n",
        "            # 这能确保保存的模型状态字典不包含 Accelerate 的包装，方便后续加载\n",
        "            unwrapped_model = accelerator.unwrap_model(model)\n",
        "            early_stopping(avg_val_loss, unwrapped_model)\n",
        "\n",
        "            if val_f1 > best_f1:\n",
        "                best_f1 = val_f1\n",
        "                accelerator.print(f\"🚀 New best macro_f1: {best_f1:.4f}. Saving model...\")\n",
        "                # 同样保存解包后的模型\n",
        "                accelerator.save(unwrapped_model.state_dict(), f\"{CFG.MODEL_OUTPUT_DIR}/best_model_fold_{fold}_f1.pth\")\n",
        "\n",
        "        # 同步所有进程，确保一个进程的早停信号能被所有进程感知\n",
        "        accelerator.wait_for_everyone()\n",
        "        if early_stopping.early_stop:\n",
        "            accelerator.print(\"Early stopping triggered. Ending training.\")\n",
        "            break\n",
        "\n",
        "    # 加载最佳模型进行最终评估或返回\n",
        "    if accelerator.is_main_process:\n",
        "        accelerator.print(f\"Training finished for fold {fold}. Best model saved at {model_path}\")\n",
        "\n",
        "    # 清理内存\n",
        "    del model, optimizer, train_loader, val_loader, scheduler\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return all_labels, all_preds\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "-4vSwdEEWi8H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CELL7"
      ],
      "metadata": {
        "id": "9SNXLtPZWi8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # ‼️ 1. 初始化 Accelerator ‼️\n",
        "    # 可以通过 `Accelerator` 的参数配置混合精度、日志等\n",
        "    # 例如: mixed_precision='fp16' 或 'bf16'\n",
        "    accelerator = Accelerator(mixed_precision='fp16', log_with=None)\n",
        "\n",
        "    # 打印 Accelerator 状态 (设备、分布式类型等)\n",
        "    accelerator.print(accelerator.state)\n",
        "\n",
        "    oof_labels = []\n",
        "    oof_preds = []\n",
        "\n",
        "    # 训练循环\n",
        "    for fold in range(1): # 改为只跑一个fold进行演示\n",
        "        # 将 accelerator 实例传递给训练函数\n",
        "        fold_labels, fold_preds = train_model(fold=fold, accelerator=accelerator)\n",
        "\n",
        "        # OOF 结果只在主进程上聚合\n",
        "        if accelerator.is_main_process:\n",
        "            oof_labels.extend(fold_labels)\n",
        "            oof_preds.extend(fold_preds)\n",
        "            accelerator.print(f\"========== FOLD {fold} FINISHED ==========\")\n",
        "            accelerator.print(f\"{'='*50}\\n\")\n",
        "\n",
        "    # 只有主进程有完整的 OOF 结果，所以绘图和最终评估也只在主进程进行\n",
        "    if accelerator.is_main_process:\n",
        "        accelerator.print(\"\\nCalculating Final Confusion Matrix for All Out-of-Fold Predictions...\")\n",
        "\n",
        "        # 类别名称列表 (请替换成你自己的)\n",
        "        class_names = [f'Gesture {i}' for i in range(CFG.NUM_CLASSES)]\n",
        "\n",
        "        cm = confusion_matrix(oof_labels, oof_preds)\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Final Confusion Matrix (Out-of-Fold Predictions)')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "        # 保存图像而不是显示，这在服务器上运行时更友好\n",
        "        plt.savefig(\"oof_confusion_matrix.png\")\n",
        "        accelerator.print(\"Confusion matrix saved to oof_confusion_matrix.png\")\n",
        "\n",
        "        oof_accuracy = accuracy_score(oof_labels, oof_preds)\n",
        "        oof_f1 = f1_score(oof_labels, oof_preds, average='macro')\n",
        "        accelerator.print(f\"\\nFinal OOF Accuracy: {oof_accuracy:.4f}\")\n",
        "        accelerator.print(f\"Final OOF Macro F1-Score: {oof_f1:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PQtyVaesWi8I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # ====================================================\n",
        "# # 8. CLEANUP (OPTIONAL)\n",
        "# # ====================================================\n",
        "# import shutil # 导入用于文件操作的库\n",
        "\n",
        "# # 检查预处理数据目录是否存在\n",
        "# if os.path.exists(CFG.PREPROCESSED_DIR):\n",
        "#     print(f\"Training finished. Now cleaning up the preprocessed data directory...\")\n",
        "#     print(f\"Directory to be removed: {CFG.PREPROCESSED_DIR}\")\n",
        "\n",
        "#     try:\n",
        "#         # 使用 shutil.rmtree 删除整个目录及其所有内容\n",
        "#         shutil.rmtree(CFG.PREPROCESSED_DIR)\n",
        "#         print(f\"Successfully removed directory: {CFG.PREPROCESSED_DIR}\")\n",
        "#     except OSError as e:\n",
        "#         print(f\"Error removing directory {CFG.PREPROCESSED_DIR}: {e.strerror}\")\n",
        "# else:\n",
        "#     print(\"Preprocessed data directory not found, no cleanup needed.\")\n",
        "\n",
        "# 验证一下磁盘空间是否释放 (可选)\n",
        "# 在Kaggle环境中，可以使用 `!df -h` 或 `!du -sh /kaggle/working/*` 来查看\n",
        "print(\"\\nVerifying working directory contents:\")\n",
        "!ls -lh /kaggle/working/\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "x7SEDB-nWi8J"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}